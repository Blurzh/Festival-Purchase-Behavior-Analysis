{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7ac120",
   "metadata": {},
   "source": [
    "### Data Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ab58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\Estudio\\Analisis de Datos\\Proyectos\\Festival Purchase Behavior Analysis\\Datasets\\festival_dataset_dirty.csv\")\n",
    "\n",
    "# This part of the code provides an overview of the dataset, spaced, so each function is easier to read.\n",
    "\n",
    "print(df.shape)\n",
    "print(\"\\n\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "print(df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "print(df.nunique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# I'm selecting columns of type 'object' (text) or 'category' to analyze unique values in those columns.\n",
    "text_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Displaying unique values for each text column\n",
    "# With it, we can see the unique values in each text column, which helps us understand the dataset better\n",
    "# And detect typos or inconsistencies in the data.\n",
    "for col in text_columns:\n",
    "    print(f\"\\nUnique values of '{col}':\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a687974",
   "metadata": {},
   "source": [
    "With this first glimpse we recognise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710549b2",
   "metadata": {},
   "source": [
    "1. Columns \"gender\" and \"ticket_type\" have null values.\n",
    "2. No duplicated rows.\n",
    "3. Unnecesary columns.\n",
    "4. Typos in columns \"payment_method\", \"favourite_genre\", \"recommend_to_friend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59620db5",
   "metadata": {},
   "source": [
    "### Removing non-essential fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"ticket_id\",\n",
    "         \"attendee_id\",\n",
    "         \"entry_time\", \n",
    "         \"purchase_date\", \n",
    "         \"was_present\", \n",
    "         \"transport_used\",\n",
    "         \"top_artist_seen\", \n",
    "         \"origin_city\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd69ea",
   "metadata": {},
   "source": [
    "### Null values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gender column ---\n",
    "# Null values management\n",
    "\n",
    "# Count the number of unique values in each column\n",
    "# Used to understand the dataset better\n",
    "print(df['gender'].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# gender_dist will store the normalized distribution\n",
    "gender_dist = df[\"gender\"].value_counts(normalize=True)\n",
    "\n",
    "# mask will be used to locate the null values in the dataset\n",
    "mask = df[\"gender\"].isnull()\n",
    "\n",
    "# Adds all the null\n",
    "n_nulls = mask.sum()\n",
    "\n",
    "# Fill the null values with random choices based on the distribution\n",
    "# This will ensure that the null values are filled in a way that reflects the original distribution\n",
    "df.loc[mask, \"gender\"] = np.random.choice(\n",
    "    gender_dist.index,\n",
    "    size=n_nulls,\n",
    "    p=gender_dist.values\n",
    ")\n",
    "\n",
    "# --- Ticket Type column ---\n",
    "# Same steps to clean \"ticket_type\" column as we followed for \"gender\" column\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "type_dist = df[\"ticket_type\"].value_counts(normalize=True)\n",
    "mask = df[\"ticket_type\"].isnull()\n",
    "n_nulls = mask.sum()\n",
    "df.loc[mask, \"ticket_type\"] = np.random.choice(\n",
    "    type_dist.index,\n",
    "    size = n_nulls,\n",
    "    p=type_dist.values\n",
    ")\n",
    "\n",
    "\n",
    "print(df[\"gender\"].value_counts(dropna=False))\n",
    "print(\"\\n\")\n",
    "print(df[\"ticket_type\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7579f",
   "metadata": {},
   "source": [
    "### Typos cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb09fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Typos cleaning ---\n",
    "\n",
    "df[\"payment_method\"] = df[\"payment_method\"].replace({\"cash \": \"Cash\"})\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"hiphop\", \"Hip-Hop\")\n",
    "df[\"favourite_genre\"] = df[\"favourite_genre\"].replace(\"Regueton\", \"Reggaeton\")\n",
    "df[\"recommend_to_friend\"] = df[\"recommend_to_friend\"].replace({\"nO\": \"No\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8527fed",
   "metadata": {},
   "source": [
    "### Trimming values with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strips leading and trailing whitespace from all string columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "      # It will convert to string, then strip whitespace\n",
    "        df[col] = df[col].str.strip()\n",
    "      # It will replace multiple spaces with a single space\n",
    "        df[col] = df[col].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022b4e8",
   "metadata": {},
   "source": [
    "### Type convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72243454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With it, we ensure that the data types are appropriate for analysis and optimize memory usage\n",
    "df = df.astype({\n",
    "    'ticket_type': 'category',\n",
    "    'ticket_price': 'int',\n",
    "    'age': 'int',\n",
    "    'gender': 'category',\n",
    "    'group_size': 'int',\n",
    "    'food_expense': 'float',\n",
    "    'drink_expense': 'float',\n",
    "    'merch_expense': 'float',\n",
    "    'payment_method': 'category',\n",
    "    'favourite_genre': 'category',\n",
    "    'stages_visited': 'int',\n",
    "    'satisfaction_score': 'int',\n",
    "    'security_rating': 'int',\n",
    "    'cleanliness_rating': 'int',\n",
    "    'recommend_to_friend': 'bool'\n",
    "})\n",
    "\n",
    "# Date conversion\n",
    "df['attendance_date'] = pd.to_datetime(df['attendance_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
